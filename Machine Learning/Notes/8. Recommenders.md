## Recommender Systems

#### Notation
- *n* is number of users
- *m* is number of items
- *d* is number of features
- *R<sub>uv</sub>* is rating given by user *u* to item *v*
- *&delta;<sub>uv</sub>* = 1 if item *v* rated by user *u*, else = 0

#### Content-Based Recommendations
- Given a feature vector x<sup>(v)</sup> for the *v*'th item
- For each user, *u*, we learn a parameter vector, *&theta;<sup>(u)</sup>*
- Training data: set of ratings, {R<sub>uv</sub>} by users of a subset of items **(each user might only rate a few items - generally sparse data)**
- **Hypothesis: predicted rating by user *u* of item *v* is:** h<sub>&theta;<sup>(u)</sup></sub>(x<sup>(v)</sup>) = (&theta;<sup>(u)</sup>)<sup>T</sup>x<sup>(v)</sup>
- Cost Function: J(&theta;<sup>(1)</sup>,...,&theta;<sup>(n)</sup>) = &Sigma;<sub>u=1</sub><sup>n</sup> &sigma;<sub>v=1</sub><sup>m</sup>&delta;<sub>uv</sub>(R<sub>uv</sub> - (&theta;<sup>(u)</sup>)<sup>T</sup>x<sup>(v)</sup>)<sup>2</sup> + &lambda;&Sigma;<sub>u=1</sub><sup>n</sup>(&theta;<sup>(u)</sup>)<sup>T</sup>&theta;<sup>(u)</sup>
  - Select &theta; to minimise - solving least squares through gradient descent, or closed form.
  
#### User-Based Recommendations
- To predict rating R<sub>uv</sub> of item *v* by user *u<sub>0</sub>* - use KNN approach
  - Find the k closest users to u<sub>0</sub>
  - Euclidean Distance d(u,u<sub>0</sub>)<br>![User based euclidean distance](../imgs/user-based-rec-euc.png)
  - Cosine Distance d(u,u<sub>0</sub>)<br>![User based cosine distance](../imgs/User-based-Cos-d.png)
- Predicted R<sub>u<sub>0</sub>v</sub> is weighted average of the rating of item v by these users
  - ![Predicted rating](../imgs/Predicted-Rating.png)
  
**Note: these data sets are generally extremely sparse, so both approaches would struggle**

#### Collaborative Filtering
- How we deal with not knowing the feature vectors
- Can find feature vectors for items using observed ratings knowing the user's preferences
- ![Collaborative Filtering](../imgs/collaborative-filtering.png)
- Define a cost metric:<br>![Cost function](../imgs/collabF-cost.png)
  - Given [&theta;] we can select [x] to minimise J
  - Given [x] we can select [&theta;] to minimise J
- Requires least squares problem solving: gradient descent, or closed-form solution
- **Predicted Rating by user *u* on item *v* is: (&theta;<sup>(u)</sup>)<sup>T</sup>x<sup>(v)</sup>**

#### Collaborative Filtering using Matrix Completion
- Gather ratings into a matrix, and attempt to predict the missing entries in R.
- Assume R is low rank d << n,m
- Hypothesis: R=U<sup>T</sup>V, but the elements of U and V are unknown
- Cost function:<br>![Matrix Completion cost](../imgs/Matrix-Completion-Cost.png)

#### Issues
- Data sparsity - particularly big issue for content/user-bassed methods:
  - Content-based: not enough ratings to estimate &theta;<sup>(u)</sup> for user u
  - User-based: or to find nearest neighbours with enough ratings
- Cold-start problem: how to recommend to a new user?
- Popularity bias: how to recommend to someone with unique tastes
  - Even with lots of data, hard to get model to generalise well
  - Intrinsic noise in recommenders e.g. Netflix people review between 3 and 5 only
- Shilling attacks/adversarial attacks - systems needed to prevent false reviews (proof of purchase/rep over time)
- Privacy - access control on data, adding noise, hiding in the crowd
