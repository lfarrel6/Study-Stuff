## This document contains the terms/formulae/stuff that I think could be asked in the exam.

## Sections
- [ML in Action](#ml-in-action)
- [Linear Regression](#linear-regression)
- [Classification](#classification)
- [Evaluation](#evaluation)

# ML in Action
- Data mining - The process of discovering patterns in large datasets
- Supervised Learning
  - Used for: Classification, Prediction/Regression
  - Takes in data with targets
  - Algorithms: KNN, SVM, Decision Trees & Random Forests
- Unsupervised Learning
  - Used for: Clustering, Dimensionality Reduction
  - Takes in: Unlabelled data
  - Alogrithms: K-Means, Hierarchical Cluster Analysis, Expected Maximization
- Semi-Supervised Learning
  - Mix of supervised and unsupervised - takes data with some labels, but mostly unlabelled
  - E.g. Google Photos - Cluster by data (faces), Target labels are sporadically assigned by the user
- Reinforcement Learning: agent observes environment, chooses action and is rewarded/penalised
- Batch/Offline Learning
  - Trained on all data - when new data is received, train on old and new - expensive
- Incremental/Online Learning
  - Trained only on new data as it becomes available - can dispose of data after training
- Model based learning 
  - Find a function which describes the existing instances
- Instance based learning
  - Find similar instances to new one, assume the values apply
- Parametric models
  - Based on features and weights e.g. linear regression
- Non-Parametric models
  - No fixed functional form, can grow in complexity to capture complicated problems
- Strengths of ML
  - Don't need large rule base, can solve complex problems, can deal with changing environment/data
- Weaknesses of ML
  - Need lots of data (not always available), can be a blackbox, legal implications, cannot unit test

# Linear Regression
- Fit a line to your data :dizzy_face:
- Hypothesis: h<sub>&theta;</sub>(x) = &theta;<sup>T</sup>x
  - Where &theta; is a vector of parameter weights, and x is our data (incl. Dummy variable x<sub>0</sub> = 1)
- Cost function: ![Linear Regression Cost](../imgs/lin-reg-cost.png)
  - Calculates the average residual
- Minimisation done through gradient descent:
  - ![Linear Regression Gradient Descent](../imgs/lin-reg-gdesc.png)
  - Where &alpha; is the learning rate, m is the size of the data set
- Normalization
  - ![Normalisation](../imgs/normalisation.png)
- Batch Gradient Descent (BGD)
  - At each iteration, BGD uses all m training data, updates all n+1 parameters
- Co-ordinate Gradient Descent (CGD)
  - At each iteration update only one param
- Stochastic Gradient Descent (SGD)
  - Loop through training set, each time updating the parameters w.r.t a single instance
- **Closed Form Solution**
  - Find &theta; that minimises J(&theta;) in closed form
  - ![Closed form](../imgs/closed-form-gdesc.png)
  - where y is the vector of targets, and X is matrix of data
- Regularization
  - Overfitting: adding more parameters, fitting to noise in dataset
  - Underfitting: poorly fitted data due to too few parameters
  - Quadratic/L2 penalty: &theta;<sup>T</sup>&theta; - encourages small values of theta - **Ridge**
  - L1 penalty: sum of absolute values of &theta; - encourages fewer elements of &theta; to be non-zero - **LASSO**
- Cross-validation for feature/model selection
  - Divide the data into chunks, and calculate &theta; for each, using it to tune the features/parameters
  - Can be used for Confidence intervals - 10 chunks = 10 samples in CI formula, take mean accuracy

# Classification
- Logistic Regression for two class problem: h<sub>&theta;</sub>(x) = sign(&theta;<sup>T</sup>x)
- &theta;<sup>T</sup>x defines: a point in one dimension, a line in two dimensions, a plane in higher dimensions
- 0-1 Loss Function: essentially counts the number of incorrect predictions and divides number of predictions
- **Loss:**
  - ![Loss function](../imgs/log-loss.png)
  - Penalties are propotional to distance from correct label
- Gradient Descent
  - Partial Deriv:<br>![Log Loss Partial Derivative](../imgs/log-reg-partial-deriv.png)
  - So starting with some &theta;...
  - ![Gradient Descent](../imgs/gradient-desc-logreg.png)
  - Where &alpha; is the learning rate
- Multiclass logistic regression
  - Train a classifier for every classifier to make it into a binary problem

# Evaluation
- Effectiveness: doing the right things
- Efficiency: doing things right - achievement per unit input
- Standard forms of evaluation: minimizing errors, maximize precision/accuracy etc.
- Offline Evaluation - Measuring success on historical data
  - RMSE, accuracy, precision etc.
- Offline Classification Metrics
  - Confusion matrix
  - Accuracy (micro): correct predictions/all predictions
  - Accuracy (macro): calculate accuracy on a per class basis
  - Log-Loss: measures the unpredictability of true distribution against the prediction distribution (how much extra noise is added by the labels)
    - ![Log Loss](../imgs/LogLoss.png)<br>Where p is the probability that the label is correct/binary indicator
  - Receiver Operating Characteristic Curve (ROC) - TP vs FP - shows how many TP are gained by accepting more FP
  - Area Under the Curve (AUC) - translates the curve to a usable value - values from 0 to 1, 0.5 is random classifier
  - Recall: true positives of all positives
  - Precision-Recall curve: plot of precision vs recall
  - F-Measure: harmonic mean of precision and recall - (&beta;<sup>2</sup> + 1) x (precision\*recall)/[(&beta;<sup>2</sup> x precision) + recall]
    - &beta; > 1 emphasizes recall, &beta; < 1 emphasizes precision
- Ranked retrieval metrics
  - Precision: p@n, precision among top n results
  - Mean Reciprocal Rank: reciprocal of the rank of the first relevant result averaged over the number of queries
  - Mean Average Precision: averages the p@n metric over a number of queries
  - Cumulative Gain: sum of the relevance of top k items, to discount divide by log2(rank+1)
- Regression Metrics
  - Mean Absolute Error (MAE): average of the absolute error between prediction/observation
  - Root Mean Squared Error (RMSE): the square root of (sum of squared errors, divided by number of instances)
- Online Metrics
  - A/B tests - showing A to 50%, B to 50%
- Splitting Methods
  - K-Fold cross validation
- Importance of Time
  - Rating performance over time
  - Considering time during training and testing - time sensitive data
- Assumption of offline data is that the data is static i.e. verifying my model on offline data will work on online data :thumbsdown:
- Gold standard
  - Analogous to monetary gold standard to compare currency value
  - In ML: best method or data under reasonable conditions
- Statistical Significance
  - Describes probability that an observed distance is by chance
  - Typical p value < 0.05 or 0.01
  - Probability of obtaining evidence
